{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xdj9KTpCgFQt"
   },
   "source": [
    "## Машинное обучение – весна 2024\n",
    "## Домашнее задание 1: kNN. Линейные модели. Работа с признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umVNVVrwgFQv"
   },
   "source": [
    "Правила:\n",
    "\n",
    "* Домашнее задание оценивается в 10 баллов.\n",
    "\n",
    "* Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n",
    "\n",
    "* Можно использовать любые свободные источники с *обязательным* указанием ссылки на них.\n",
    "\n",
    "* Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
    "\n",
    "* Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_YUJjw3gFQv"
   },
   "source": [
    "### Задание 1:  Визуализация решающих поверхностей в kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaS6e29EgFQw"
   },
   "source": [
    "В этом задании мы изобразим решающую поверхность для классификатора kNN, чтобы наглядно увидеть, как классификатор принимает решения для новых объектов. Для простоты будем работать со встроенным в `sklearn` набором данных `wine`, содержащим информацию о характеристиках трёх видов вина. Описание набора можно найти [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) и [здесь](https://rdrr.io/cran/rattle.data/man/wine.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygPNcrxSgFQw"
   },
   "source": [
    "Загрузим набор данных и сохраним информацию о признаках в переменную `X`, а о зависимой переменной – в переменную `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7fgg6HGlgFQw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "VxWqG3fWgFQw",
    "outputId": "b2450c6f-c2ed-4ae8-e546-8a3d84636289"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "5    14.20        1.76  2.45               15.2      112.0           3.27   \n",
       "6    14.39        1.87  2.45               14.6       96.0           2.50   \n",
       "7    14.06        2.15  2.61               17.6      121.0           2.60   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "5        3.39                  0.34             1.97             6.75  1.05   \n",
       "6        2.52                  0.30             1.98             5.25  1.02   \n",
       "7        2.51                  0.31             1.25             5.05  1.06   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  \n",
       "5                          2.85   1450.0  \n",
       "6                          3.58   1290.0  \n",
       "7                          3.58   1295.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data = load_wine()\n",
    "X = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "y = data['target']\n",
    "X.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_U56JgAgFQx"
   },
   "source": [
    "**Задача 1.1 (0.5 балла)** Есть ли в наборе данных пропущенные значения? Если да, то удалите их. Есть ли в наборе данных категориальные переменные? Если да, то закодируйте их при помощи OneHot-кодирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fiSpOONkgFQx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                         False\n",
       "malic_acid                      False\n",
       "ash                             False\n",
       "alcalinity_of_ash               False\n",
       "magnesium                       False\n",
       "total_phenols                   False\n",
       "flavanoids                      False\n",
       "nonflavanoid_phenols            False\n",
       "proanthocyanins                 False\n",
       "color_intensity                 False\n",
       "hue                             False\n",
       "od280/od315_of_diluted_wines    False\n",
       "proline                         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в данных нет пропусков\n",
    "X.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# если бы пропуски были\n",
    "X_no_mis = X.dropna()\n",
    "X_no_mis.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в наборе нет категориальных признаков\n",
    "sum(X.dtypes == \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если бы признаки были\n",
    "X_dum = pd.get_dummies(X, drop_first = True)\n",
    "X_dum.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9ormdqggFQx"
   },
   "source": [
    "**Задача 1.2 (0.5 балла)** Используя функцию `train_test_split()`, разделите выборку на тренировочную и тестовую, и долю тестовой выборки задайте равной 0.3. Так как разбиение осуществляется случайным образом, не забудьте зафиксировать `np.random.seed()` для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ejTIGB2gFQx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wMtxXo1gFQx"
   },
   "source": [
    "**Задача 1.3 (1 балл)** На тренировочной выборке обучите шесть классификаторов kNN, отличающихся только числом соседей. Для первого классификатора число соседей поставьте равным 1, для второго - 3, для третьего – 5, для четвертого – 10, для пятого – 15 и для шестого – 25 (обратите внимание на параметр `n_neighbours` класса `KNeighborsClassifier`). Для обучения используйте только два признака: `alcohol` и `magnesium` – и евклидово расстояние. Не забудьте масштабировать признаки, например, при помощи модуля `StandardScaler`.\n",
    "\n",
    "Выведите долю правильных ответов на тренировочной и тестовой выборках для каждого классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LHvC2Bt3ZwD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkHDPUusgFQy",
    "outputId": "bea1e0ae-df2f-4015-a1ea-b84c78de857e"
   },
   "outputs": [],
   "source": [
    "# выбор признаков\n",
    "X_train_sel = X_train[[\"alcohol\", \"magnesium\"]]\n",
    "X_test_sel = X_test[[\"alcohol\", \"magnesium\"]]\n",
    "\n",
    "# масштабирование признаков\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_sel)\n",
    "X_train_transform = scaler.transform(X_train_sel)\n",
    "X_test_transform = scaler.transform(X_test_sel)\n",
    "\n",
    "# обучение классификатора и предсказания\n",
    "number_of_neighbours = np.array([1, 3, 5, 10, 15, 25])\n",
    "test, train, clfs = [], [], []\n",
    "\n",
    "for i in range(len(number_of_neighbours)):\n",
    "    k = number_of_neighbours[i]\n",
    "    clf = KNeighborsClassifier(n_neighbors = k).fit(X_train_transform, y_train)\n",
    "    clfs.append(clf)\n",
    "    y_predicted_train = clf.predict(X_train_transform)\n",
    "    y_predicted = clf.predict(X_test_transform)\n",
    "    \n",
    "    train.append(np.mean(y_predicted_train == y_train).round(2))\n",
    "    test.append(np.mean(y_predicted == y_test).round(2))\n",
    "    \n",
    "pd.DataFrame({'NN': number_of_neighbours, 'Train': train, 'Test': test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV1qB23NgFQy"
   },
   "source": [
    "**Задача 1.4 (0 баллов)** Установите библиотеку `mlxtend` командой ниже. Библиотеку также можно установить из терминала при помощи `pip` или `conda`, как указано [здесь](http://rasbt.github.io/mlxtend/installation/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oh8XCW-lgFQy"
   },
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPp6UcyZgFQy"
   },
   "source": [
    "Если всё прошло успешно, то в выводе команды выше вы увидите сообщение вроде \"successfully installed\", а следующая ячейка выполнится без ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PX5FraBQgFQy"
   },
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbKw2dSVgFQy"
   },
   "source": [
    "**Задача 1.5 (1 балл)** Библиотека `mlxtend` позволяет достаточно просто визуализировать решающие поверхности обученных классификаторов. Изучите [документацию](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/) библиотеки и найдите, как можно построить несколько графиков решающих поверхностей на сетке (decision regions grid). Постройте такую сетку графиков для обученных выше классификаторов.\n",
    "\n",
    "**Подсказки:**\n",
    "1. Вы можете использовать готовый код, приведённый в документации, и адаптировать его для нашего случая.\n",
    "2. Вам могут понадобиться дополнительные библиотеки, которые используются в примере из документации.\n",
    "3. Обратите внимание на то, как нужно изменить параметры `gridspec.GridSpec()` и `itertools.product()` для нашего числа классификаторов. \n",
    "4. В функции `plot_decision_region()` используйте `y_train` и нужные столбцы из `X_train`. Возможно, их придётся перевести в формат массива `numpy`.\n",
    "5. Если в задаче 1.3 вы сохраните обученные классификаторы в список, то не будет необходимости обучать их заново. \n",
    "6. Построение графика может занять некоторое время – придётся немного подождать!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wCCxJpegFQy",
    "outputId": "a42c1bde-6acd-4fa6-fe74-482a25fa3db9"
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "gs = gridspec.GridSpec(2, 3)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "labels = []\n",
    "\n",
    "for i in range(len(number_of_neighbours)):\n",
    "    k = number_of_neighbours[i]\n",
    "    labels.append(f'n_neighbours = {k}')\n",
    "    \n",
    "for clf, lab, grd in zip(clfs,\n",
    "                         labels,\n",
    "                         itertools.product([0, 1, 2], repeat=2)):\n",
    "\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X_train_transform, y=y_train, clf=clf, legend=2)\n",
    "    plt.title(lab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUEKOeVZgFQy"
   },
   "source": [
    "**Задача 1.6 (0.5 балла)** Прокомментируйте результаты, полученные в задачах 1.3 и 1.5. Какое число соседей оптимально использовать для обучения классификатора? Поясните ваш выбор при помощи описания геометрии данных и получаемой решающей поверхности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1FAYqb1gFQ0"
   },
   "source": [
    "По результатам задачи 1.3 наибольшую долю верных ответов (accuracy) на тестовой выборке имеет число соседей равное 10. \n",
    "Из графиков задачи 1.5 можно прийти к схожим выводам. При k = 1 модель переобучена, так как каждый (даже отдельно стоящий - скорее всего шумовой) элемент обучающей выборки порождает область \"своего цвета\". Это говорит о том что модель плохо отражает общую картину расположения объектов тренировочной выборки. Примерно то же самое можно сказать про k = 3 - отдельно взятые небольшие группы объектов сильно влияют на конфигурацию решающей поверхности. При k = 25 модель напротив недообучена, так как данные довольно сильно перемешаны и график плохо отражает расположение объектов тренировочной выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehRtcRN3kMgW"
   },
   "source": [
    "### Задание 2. KNN своими руками. 2 Балла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y38gBPr1ms8c"
   },
   "source": [
    "В данном задании мы попробуем реализовать алгоритм KNN своими руками. В данном случае мы попробуем сделать KNN для классификации.\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIsIhp97mXIC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter \n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class KNN(BaseEstimator):\n",
    "    def __init__(self, k:int):\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        answer = []\n",
    "        for x in X:\n",
    "            distances = []\n",
    "            for el in self.X:\n",
    "                distances.append(np.sqrt(np.sum((x-el)*(x-el))))\n",
    "            distances = np.array(distances)\n",
    "            nearest_ind = np.argsort(distances)[:self.k]\n",
    "            nearest_ans = self.y[nearest_ind]\n",
    "            c = Counter(nearest_ans)\n",
    "            answer.append(max(c, key=c.get))\n",
    "        return np.array(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rd0NbTxGmWDE"
   },
   "outputs": [],
   "source": [
    "# Не меняйте файл!\n",
    "def test_knn(KNN):\n",
    "  knn = KNN(k=1)\n",
    "  X_train =  np.array([[1, 1], [2, 2]])\n",
    "  y_train =  np.array([0, 1])\n",
    "  X_test =  np.array([[1.5, 1.5]])\n",
    "  knn.fit(X_train, y_train)\n",
    "  assert knn.predict(X_test) == [0]\n",
    "\n",
    "  knn = KNN(k=3)\n",
    "  X_train = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10]])\n",
    "  y_train = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "  X_test = np.array([[9.5, 9.5]])\n",
    "  knn.fit(X_train, y_train)\n",
    "  assert knn.predict(X_test) == [1]\n",
    "\n",
    "  knn = KNN(k=3)\n",
    "  X_train = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10]])\n",
    "  y_train = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "  X_test = np.array([[5.5, 5.5]])\n",
    "  knn.fit(X_train, y_train)\n",
    "  assert knn.predict(X_test) == [1]\n",
    "\n",
    "  knn = KNN(k=3)\n",
    "  X_train = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10]])\n",
    "  y_train = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "  X_test = np.array([[15, 15]])\n",
    "  knn.fit(X_train, y_train)\n",
    "  assert knn.predict(X_test) == [1]\n",
    "\n",
    "  knn = KNN(k=3)\n",
    "  X_train = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10]])\n",
    "  y_train = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "  X_test = np.array([[5, 5], [2, 2]])\n",
    "  knn.fit(X_train, y_train)\n",
    "  assert all(knn.predict(X_test) == [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSLcovKGr7nB"
   },
   "outputs": [],
   "source": [
    "# Если тесты эти пройдены, то все верно!\n",
    "test_knn(KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeRb5fnjgFQ1"
   },
   "source": [
    "### Задание 3: Линейная регрессия своими руками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b3qyhPBgFQ1"
   },
   "source": [
    "В этом задании мы попробуем реализовать алгоритм линейной регрессии своими руками и рассмотрим различные аспекты построения линейной модели. Мы будем работать с одним из классических наборов данных в статистике, содержащим информацию о бриллиантах. Описание можно посмотреть [здесь](https://www.kaggle.com/shivam2503/diamonds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMxJH2wUgFQ1",
    "outputId": "704954e2-dcdf-4f21-e538-aecf8817904c"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/diamonds.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "up0aSDWUgFQ1"
   },
   "source": [
    "Мы будем решать задачу на примере предсказания цены бриллианта `price` в зависимости от его характеристик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.0 (2 балла)** Реализуйте алгоритм линейной регресии (базовой, без регуляризации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Linreg(BaseEstimator):    \n",
    "    def fit(self, X, y):\n",
    "        Xl = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        Xl_t = np.transpose(Xl)\n",
    "        w = np.dot(np.dot(np.linalg.inv(np.dot(Xl_t, Xl)), Xl_t), y)\n",
    "        self.w = w[1:]\n",
    "        self.const = w[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.w) + self.const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0miSmx6mgFQ1"
   },
   "source": [
    "**Задача 3.1 (0.1 балла)** Есть ли в наборе данных пропущенные значения? Если да, удалите их. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yb_iI9RigFQ1"
   },
   "outputs": [],
   "source": [
    "# в данных нет пропусков\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если бы пропуски были\n",
    "data_no_mis = data.dropna()\n",
    "data_no_mis.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U65dKBUAgFQ1"
   },
   "source": [
    "**Задача 3.2 (0.1 балла)** Есть ли в наборе данных бессмысленные столбцы (признаки, не несущие дополнительной информации)? Если да, то удалите их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8i41WY4gFQ1"
   },
   "outputs": [],
   "source": [
    "# бессмысленный столбец - столбец с нумерацией, так как он не несет никакой информации для определения цены бриллианта, и у DataFrame есть собственная нумерация\n",
    "data = data.drop('Unnamed: 0', axis = 1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyTZyrrfgFQ1"
   },
   "source": [
    "**Задача 3.3 (0.2 балла)** Линейная регрессия основана на предположении о линейной связи между признаками и целевой переменной, а потому перед выбором переменных для включения в модель имеет смысл проверить, насколько эта связь выполняется. Для следующих пунктов нам также потребуются выборочные корреляции между признаками. Выведите матрицу выборочных корреляций между всеми вещественными признаками и целевой переменной (то есть в этой матрице будет $k+1$ строка, где $k$ – количество вещественных признаков).\n",
    "\n",
    "Какие вещественные признаки коррелируют с целевой переменной больше всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJiOlnVkgFQ1"
   },
   "outputs": [],
   "source": [
    "# выбор вещественных признаков\n",
    "cat_feature_mask = (data.dtypes == \"object\").values\n",
    "data_real = data[data.columns[~cat_feature_mask]]\n",
    "\n",
    "# корелляция между целевой переменной price и признаками\n",
    "print(data_real.corrwith(data_real['price']), '\\n')\n",
    "\n",
    "print(data.corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сильнее всего с целевой переменной кореллериуют количество карат и размеры алмаза по x, y, z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49JVZnTUgFQ2"
   },
   "source": [
    "**Задача 3.4 (0.1 балла)** Так как линейная модель складывает значения признаков с некоторыми весами, нам нужно аккуратно обработать категориальные признаки. Закодируйте категориальные переменные при помощи OneHot-кодирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uujOkneZgFQ2"
   },
   "outputs": [],
   "source": [
    "# в наборе есть категориальные признаки\n",
    "sum(data.dtypes == \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot-кодирование\n",
    "data_dum = pd.get_dummies(data, drop_first = True, dtype = int)\n",
    "data_dum.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AP2Ejcg-gFQ2"
   },
   "source": [
    "**Задача 3.5 (0.1 балла)** Разделите выборку на тренировочную и тестовую. Долю тестовой выборки укажите равной 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Fx0sgtvgFQ2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_dum.drop(['price'], axis = 1)\n",
    "y = data_dum['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcUS-idKgFQ2"
   },
   "source": [
    "**Задача 3.6 (0.1 балла)** Зачастую при использовании линейных моделей вещественные признаки масштабируются. При этом оценки коэффициентов теряют прямую статистическую интерпретацию (\"при увеличении $X_1$ на 1, $y$ увеличивается на $w_1$\"), но приобретают свойства, полезные в задачах машинного обучения. В этой задаче масштабируйте вещественные признаки тренировочной и тестовой выборок при помощи модуля `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrzWDPivgFQ2"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "real_columns = np.array(data.dtypes[data.dtypes == 'float64'].index)\n",
    "\n",
    "X_train_transform = X_train.copy()\n",
    "X_test_transform = X_test.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_transform[real_columns])\n",
    "\n",
    "X_train_transform[real_columns] = scaler.transform(X_train_transform[real_columns])\n",
    "X_test_transform[real_columns] = scaler.transform(X_test_transform[real_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7epyRtVgFQ2"
   },
   "source": [
    "**Задача 3.7 (0.1 балла)** Оцените линейную регрессию на тренировочной выборке. Выведите среднеквадратичную ошибку на тренировочной и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6JrJ6UfgFQ2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_transform, y_train)\n",
    "y_predict_train = linreg.predict(X_train_transform)\n",
    "y_predict = linreg.predict(X_test_transform)\n",
    "\n",
    "# mean squared error на тренировочной и тестовой выборках\n",
    "print(f'MSE на тренировочной выборке: {mean_squared_error(y_train, y_predict_train).round(2)}')\n",
    "print(f'MSE на тестовой выборке: {mean_squared_error(y_test, y_predict).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dN17tJ7LgFQ2"
   },
   "source": [
    "**Задача 3.8 (0.2 балла)** Изучите документацию модуля `LinearRegression` и выведите полученные оценки коэффициентов. Назовите вещественные переменные, оценки коэффициентов которых по модулю на порядок превышают оценки прочих вещественных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCjyJCiNgFQ2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# оценки коффициентов\n",
    "lr = LinearRegression().fit(X_train_transform, y_train)\n",
    "print(lr.coef_, '\\n')\n",
    "\n",
    "# вещественные переменные, оценки коэффициентов которых по модулю на порядок больше\n",
    "deg = np.log10(abs(lr.coef_[:6])).astype(int)\n",
    "X_train_real = X_train.columns[:6]\n",
    "names = X_train_real[deg == max(deg)]\n",
    "print(*names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWzWm834gFQ2"
   },
   "source": [
    "**Задача 3.9 (0.2 балла)** Как можно заметить из анализа корреляционной матрицы в задаче 3.3, между некоторыми признаками имеется сильная корреляция, что может быть индикатором проблемы *мультиколлинеарности*. Различия в порядке коэффициентов, выявленные в предыдущей задаче также намекают на её присутствие. Как известно, для решения этой проблемы можно либо исключить некоторые признаки из модели, либо использовать регуляризацию. Мы воспользуемся вторым вариантом. \n",
    "\n",
    "Вспомним, что смысл регуляризации заключается в том, чтобы изменить функцию потерь так, чтобы устранить проблемы, появляющиеся из-за мультиколлинеарности. При L1-регуляризации предлагается минимизировать следующую функцию потерь:\n",
    "\n",
    "$$\n",
    "\\|y - X\\hat{w}\\|^2 + \\alpha\\sum_{i=1}^k|w_i|\n",
    "$$\n",
    "\n",
    "Такая модель называется Lasso-регрессией.\n",
    "\n",
    "При L2-регуляризации предлагается минимизировать следующую функцию потерь:\n",
    "\n",
    "$$\n",
    "\\|y - X\\hat{w}\\|^2 + \\frac{1}{2}\\alpha\\|w\\|^2\n",
    "$$\n",
    "\n",
    "Такая модель называется Ridge-регрессией. \n",
    "\n",
    "Обучите Lasso-регрессию и Ridge-регрессию, уставновив гиперпараметр регуляризации равным 10. Для этого используйте модули `Lasso` и `Ridge` из `sklearn`. Сильно ли уменьшились веса? Сделайте вывод о том, насколько сильно проблема мультиколлинеарности проявлялась в изначальной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeA2LWLagFQ2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "lasso = Lasso(10).fit(X_train_transform, y_train)\n",
    "ridge = Ridge(10).fit(X_train_transform, y_train)\n",
    "\n",
    "print(f'Lasso-регрессия:\\n {lasso.coef_} \\n')\n",
    "print(f'Ridge-регрессия:\\n {ridge.coef_} \\n')\n",
    "\n",
    "print(f'Отличие весов Lasso-регрессии от весов линейной регрессии: {np.mean(lr.coef_ - lasso.coef_).round(3)}')\n",
    "print(f'Отличие весов Ridge-регрессии от весов линейной регрессии: {np.mean(lr.coef_ - ridge.coef_).round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса более значительно уменьшились при применении Lasso-регрессии, чем при применении Ridge-регрессии.\n",
    "Так как веса уменьшились незначительно с обеими регуляризациями, проблема мультиколлинеарности вероятно была незначительной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DftPGQdkgFQ3"
   },
   "source": [
    "**Задача 3.10 (0.5 балла)** Как обсуждалось на семинарах, Lasso-регрессию можно использовать для отбора наиболее информативных признаков. Для следующих значений параметра регуляриазции $\\alpha$: 0.1, 1, 10, 100, 200 –  обучите Lasso- и Ridge-регрессии и постройте график измненения евклидовой нормы весов (`np.linalg.norm()` от вектора оценок коэффициентов) в зависимости от параметра $\\alpha$. Как известно, норма является численной характеристикой величины вектора, а потому по норме можно судить о том, насколько большие элементы содержит вектор оценок коэффициентов. \n",
    "\n",
    "Какой метод агрессивнее уменьшает веса? Поясните, почему Lasso-регрессию часто используют для отбора признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lT_Vob-2gFQ3"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "alphas = [0.1, 1, 10, 100, 200]\n",
    "lasso = np.empty(5)\n",
    "ridge = np.empty(5)\n",
    "\n",
    "for i in range(len(alphas)):\n",
    "    alpha = alphas[i]\n",
    "    lasso[i] = np.linalg.norm(Lasso(alpha=alpha).fit(X_train_transform, y_train).coef_)\n",
    "    ridge[i] = np.linalg.norm(Ridge(alpha=alpha).fit(X_train_transform, y_train).coef_)\n",
    "    \n",
    "plt.plot(alphas, lasso, label='Lasso', color = 'g')\n",
    "plt.plot(alphas, ridge, label='Ridge', color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso-регрессия aгрессивнее уменьшает веса и даже зануляет часть весов. Таким образом можно избавиться от признаков\n",
    "(с зануленными весами) в линейной модели, что упрощает модель и помогает в решении проблемы мультиколлинеарности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0iVRfS1gFQ3"
   },
   "source": [
    "**Задача 3.11 (0.5 балла)** \n",
    "В зависимости от значения параметра $\\alpha$ в Lasso-регрессии зануляются разные оценки коэффициентов. Оптимальное значение $\\alpha$ можно подобрать, например, при помощи кросс-валидации по тренировочной выборке. \n",
    "\n",
    "Для проведения кросс-валидации можно использовать модуль `LassoCV`. Этот модуль принимает список значений $\\alpha$ (параметр `alphas`) и при обучении проводит кросс-валидацию для каждого значения из этого списка, сохраняя MSE на каждом участке кросс-валидации (количество участков – параметр `cv`) в матрицу ошибок (то есть итоговая матрица будет иметь размер `len(alphas)` $\\times$ `cv`). После обучения модели матрицу ошибок можно получить, обратившись к атрибуту `.mse_path_`. \n",
    "\n",
    "Заметим, что модель может использовать $\\alpha$ не в том порядке, в котором вы подаёте их в функцию: для определения порядка используйте атрибут `.alphas_` Установите количество участков для кросс-валидации (параметр `cv`) равным 5.\n",
    "\n",
    "Усредните ошибки для каждого значения $\\alpha$ (то есть по строкам матрицы ошибок) и выберите то значение, которое даёт наибольшее качество. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMwL5-Y4gFQ3"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "alphas = [0.1, 1, 10, 100, 200]\n",
    "lasso_cv = LassoCV(alphas = alphas, cv = 5).fit(X_train_transform, y_train)\n",
    "\n",
    "print(f'Матрица ошибок:\\n {lasso_cv.mse_path_} \\n')\n",
    "print(f'Порядок значений alpha:\\n {lasso_cv.alphas_} \\n')\n",
    "\n",
    "mean = lasso_cv.mse_path_.mean(axis = 1).round(2)\n",
    "print(f'Усредненные ошибки для каждого alpha:\\n {mean} \\n')\n",
    "print(f'Наилучшее значение alpha:\\n {lasso_cv.alphas_[np.argmin(mean)]} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVUxxxhYgFQ3"
   },
   "source": [
    "**Задача 3.12 (0.1 балла)** Обучите итоговую Lasso-регрессию с выбранным параметром $\\alpha$ на тренировочной выборке. Выведите полученные коэффициенты и прокомментируйте, какие признаки оказались неинформативными, а какие – наиболее информативными. Приведите возможное смысловое объяснение этого результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQtobJcQgFQ3"
   },
   "outputs": [],
   "source": [
    "final_lasso = Lasso(1).fit(X_train_transform, y_train)\n",
    "print(final_lasso.coef_, '\\n')\n",
    "print(pd.DataFrame(data = dict(zip(list(X_train.columns), final_lasso.coef_)), index = ['coefs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неинформативными оказались размер алмаза по y и z, а также слабо информативен table. Наиболее информативны - carat, clarity_IF,\n",
    "clarity_VVS1, clarity_VVS2, clarity_VS1.\n",
    "Возможно y, z оказались неинформативными из-за наличия корреляции с carat, категориальные признаки настолько информативны так как\n",
    "они слабо кореллируют друг с другом и с остальными переменными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cef0Qif4gFQ3"
   },
   "source": [
    "**Задача 3.13 (0.2 балла)** Сделайте предсказания обученной Lasso-регрессии на тестовой выборке и сравните среднеквадратичную ошибку с ошибкой обычной линейной регрессии из задачи 3.7. Какую модель лучше использовать для предсказаний? Приведите возможное объяснение, почему одна модель оказалась лучше другой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCgns9cigFQ3"
   },
   "outputs": [],
   "source": [
    "y_predict_lasso = final_lasso.predict(X_test_transform)\n",
    "print(f'MSE Lasso: {mean_squared_error(y_test, y_predict_lasso).round(2)}')\n",
    "print(f'MSE обычной регрессии: {mean_squared_error(y_test, y_predict).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше использовать обычную регрессию, так как ее MSE меньше. Возможная причина этого в том, что данные имеют мало выбросов и хорошо удовлетворяют линейной модели."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
